{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T08:07:55.060371Z",
     "start_time": "2020-11-29T08:07:55.037978Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "utils.load_extension(\"collapsible_headings/main\")\n",
       "utils.load_extension(\"hide_input/main\")\n",
       "utils.load_extension(\"autosavetime/main\")\n",
       "utils.load_extension(\"execute_time/ExecuteTime\")\n",
       "utils.load_extension(\"code_prettify/code_prettify\")\n",
       "utils.load_extension(\"scroll_down/main\")\n",
       "utils.load_extension(\"jupyter-js-widgets/extension\")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "utils.load_extension(\"collapsible_headings/main\")\n",
    "utils.load_extension(\"hide_input/main\")\n",
    "utils.load_extension(\"autosavetime/main\")\n",
    "utils.load_extension(\"execute_time/ExecuteTime\")\n",
    "utils.load_extension(\"code_prettify/code_prettify\")\n",
    "utils.load_extension(\"scroll_down/main\")\n",
    "utils.load_extension(\"jupyter-js-widgets/extension\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T08:07:58.330263Z",
     "start_time": "2020-11-29T08:07:55.067679Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from category_encoders import TargetEncoder\n",
    "\n",
    "plt.style.use(\"seaborn\")\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from nnet import ReadDataset, Net,ResNet\n",
    "import time\n",
    "from loss_functions import interval_score_loss\n",
    "\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "from gauss_rank_scaler import GaussRankScaler\n",
    "tic = time.time()\n",
    "from models.lgbm import (compute_metrics, preprocess)\n",
    "\n",
    "from tools.metrics import (\n",
    "    get_avg_volumes,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T08:07:58.393425Z",
     "start_time": "2020-11-29T08:07:58.386707Z"
    }
   },
   "outputs": [],
   "source": [
    "def my_metric(pred, lower, upper):\n",
    "\n",
    "    metric_pair = compute_metrics(\n",
    "        preds=pred,\n",
    "        lower=lower,\n",
    "        upper=upper,\n",
    "        y=val_y_raw,\n",
    "        offset=val_offset,\n",
    "        X=val_x_orig,\n",
    "        avg_volumes=avg_volumes,\n",
    "    )\n",
    "    return metric_pair[0],metric_pair[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T08:07:58.423674Z",
     "start_time": "2020-11-29T08:07:58.407184Z"
    }
   },
   "outputs": [],
   "source": [
    "def postprocess_submission(submission_df, solve_submission_issues=True):\n",
    "\n",
    "    join_on = [\"country\", \"brand\", \"month_num\"]\n",
    "    keep = join_on + [\"volume\"]\n",
    "\n",
    "    df_vol = pd.read_csv(\"../data/gx_volume.csv\").loc[:, keep]\n",
    "\n",
    "    both_ds = submission_df.merge(\n",
    "        df_vol,\n",
    "        on=join_on,\n",
    "        how=\"left\",\n",
    "    )\n",
    "\n",
    "    both_ds.loc[both_ds[\"volume\"].notnull(), \"prediction\"] = both_ds[both_ds[\"volume\"].notnull()][\"volume\"].values\n",
    "    both_ds.loc[both_ds[\"volume\"].notnull(), \"pred_95_high\"] = both_ds[both_ds[\"volume\"].notnull()][\"volume\"].values + 0.01\n",
    "    both_ds.loc[both_ds[\"volume\"].notnull(), \"pred_95_low\"] = both_ds[both_ds[\"volume\"].notnull()][\"volume\"].values - 0.01\n",
    "\n",
    "    final_cols = join_on + [\"pred_95_low\", \"prediction\", \"pred_95_high\"]\n",
    "\n",
    "    final_df =  both_ds.loc[:, final_cols]\n",
    "\n",
    "    if solve_submission_issues:\n",
    "\n",
    "        if (final_df.pred_95_low > final_df.pred_95_high).any():\n",
    "            raise(\"Stop please, upper < lower\")\n",
    "\n",
    "        cond_lower_mean = final_df.pred_95_low > final_df.prediction\n",
    "        if cond_lower_mean.any():\n",
    "            print(\"Solving lower > mean\")\n",
    "            final_df.loc[cond_lower_mean, \"prediction\"] = \\\n",
    "                final_df.loc[cond_lower_mean, \"pred_95_low\"] + 0.01\n",
    "\n",
    "        cond_upper_mean = final_df.prediction > final_df.pred_95_high\n",
    "        if cond_upper_mean.any():\n",
    "            print(\"Solving upper < mean\")\n",
    "            final_df.loc[cond_upper_mean, \"prediction\"] = \\\n",
    "                final_df.loc[cond_upper_mean, \"pred_95_high\"] - 0.01\n",
    "\n",
    "\n",
    "    return final_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T08:07:58.442107Z",
     "start_time": "2020-11-29T08:07:58.437160Z"
    }
   },
   "outputs": [],
   "source": [
    "def my_metric(pred, lower, upper):\n",
    "\n",
    "    metric_pair = compute_metrics(\n",
    "        preds=pred,\n",
    "        lower=lower,\n",
    "        upper=upper,\n",
    "        y=val_y_raw,\n",
    "        offset=val_offset,\n",
    "        X=val_x_orig,\n",
    "        avg_volumes=avg_volumes,\n",
    "    )\n",
    "    return metric_pair[0],metric_pair[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T08:08:00.054124Z",
     "start_time": "2020-11-29T08:07:58.448109Z"
    }
   },
   "outputs": [],
   "source": [
    "file_name = \"linear_base\"\n",
    "offset_name = \"last_before_3_after_0\"\n",
    "full_df = pd.read_csv(\"../data/gx_merged_lags_months.csv\")\n",
    "    # volume_features = pd.read_csv(\"data/volume_features.csv\")\n",
    "submission_df = pd.read_csv(\"../data/submission_template.csv\")\n",
    "train_tuples = pd.read_csv(\"../data/train_split.csv\")\n",
    "valid_tuples = pd.read_csv(\"../data/valid_split.csv\")\n",
    "\n",
    " \n",
    "# full_df = full_df.merge(volume_features, on=[\"country\", \"brand\"])\n",
    "\n",
    "\n",
    "full_df[\"volume_offset\"] = (full_df[\"volume\"] - full_df[offset_name]) / full_df[offset_name]\n",
    "full_df = preprocess(full_df)\n",
    "\n",
    "test_df = full_df[full_df.test == 1].copy().reset_index(drop=True)\n",
    "\n",
    "real_full = full_df.copy()\n",
    "\n",
    "full_df = full_df[full_df.test == 0]\n",
    "\n",
    "train_df = full_df.merge(train_tuples, how=\"inner\").reset_index(drop=True)\n",
    "val_df = full_df.merge(valid_tuples, how=\"inner\").reset_index(drop=True)\n",
    "\n",
    "    # TODO: no need for calculation every time\n",
    "avg_volumes = get_avg_volumes()\n",
    "\n",
    "to_drop = [\"volume\", \"volume_offset\",'test','A','country_mean_before_24_after_0']\n",
    "categorical_cols = [\n",
    "        \"country\", \"brand\", \"therapeutic_area\", \"presentation\", \"month_name\",\n",
    "        \"month_country\", \"month_presentation\", \"month_area\",\n",
    "        \"month_country_num\", \"month_presentation_num\", \"month_area_num\",\n",
    "        \"month_month_num\"\n",
    "    ]\n",
    "\n",
    "    # Prep data\n",
    "train_x = train_df.drop(columns=to_drop)\n",
    "train_y = train_df.volume_offset\n",
    "train_offset = train_df[offset_name]\n",
    "\n",
    "\n",
    "\n",
    "full_x = full_df.drop(columns=to_drop)\n",
    "full_y = full_df.volume_offset\n",
    "full_offset = full_df[offset_name]\n",
    "\n",
    "real_full_x = real_full.drop(columns=to_drop)\n",
    "\n",
    "\n",
    "val_x = val_df.drop(columns=to_drop)\n",
    "val_x_orig = val_x\n",
    "val_y = val_df.volume_offset\n",
    "val_y_raw = val_df.volume\n",
    "val_offset = val_df[offset_name]\n",
    "\n",
    "test_x = test_df.drop(columns=to_drop)\n",
    "test_offset = test_df[offset_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T08:08:00.081597Z",
     "start_time": "2020-11-29T08:08:00.070707Z"
    }
   },
   "outputs": [],
   "source": [
    "from category_encoders.one_hot import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T08:08:08.034447Z",
     "start_time": "2020-11-29T08:08:00.111256Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/category_encoders/utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(cols=['country', 'brand', 'therapeutic_area', 'presentation',\n",
       "                    'month_name', 'month_country', 'month_presentation',\n",
       "                    'month_area', 'month_country_num', 'month_presentation_num',\n",
       "                    'month_area_num', 'month_month_num'],\n",
       "              drop_invariant=False, handle_missing='value',\n",
       "              handle_unknown='value', return_df=True, use_cat_names=False,\n",
       "              verbose=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "categorical_cols = [\n",
    "        \"country\", \"brand\", \"therapeutic_area\", \"presentation\", \"month_name\",\n",
    "        \"month_country\", \"month_presentation\", \"month_area\",\n",
    "        \"month_country_num\", \"month_presentation_num\", \"month_area_num\",\n",
    "        \"month_month_num\"\n",
    "    ]\n",
    "te = OneHotEncoder(cols=categorical_cols)\n",
    "te.fit(full_x,full_y)\n",
    "#te.fit(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T08:08:29.218512Z",
     "start_time": "2020-11-29T08:08:08.038341Z"
    }
   },
   "outputs": [],
   "source": [
    "full_x = te.transform(full_x)\n",
    "train_x = te.transform(train_x)\n",
    "val_x = te.transform(val_x)\n",
    "test_x= te.transform(test_x)\n",
    "\n",
    "real_full_x =te.transform(real_full_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T08:08:29.256318Z",
     "start_time": "2020-11-29T08:08:29.247826Z"
    }
   },
   "outputs": [],
   "source": [
    "scaler = GaussRankScaler()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T08:08:31.882747Z",
     "start_time": "2020-11-29T08:08:29.274607Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussRankScaler(copy=True, epsilon=0.0001, interp_copy=False,\n",
       "                interp_kind='linear', n_jobs=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scaler.fit(train_x)\n",
    "scaler.fit(real_full_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T08:08:49.523971Z",
     "start_time": "2020-11-29T08:08:32.003949Z"
    }
   },
   "outputs": [],
   "source": [
    "full_x = pd.DataFrame(scaler.transform(full_x),columns=full_x.columns)\n",
    "train_x = pd.DataFrame(scaler.transform(train_x),columns=full_x.columns)\n",
    "val_x = pd.DataFrame(scaler.transform(val_x),columns=full_x.columns)\n",
    "test_x = pd.DataFrame(scaler.transform(test_x),columns=full_x.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T08:08:49.535836Z",
     "start_time": "2020-11-29T08:08:49.526193Z"
    }
   },
   "outputs": [],
   "source": [
    "class ReadDataset(Dataset):\n",
    "    \"\"\"Read dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, XX,yy):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (str): Path to the csv file with the students data.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        self.X = XX\n",
    "        self.y = yy\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __shape__(self):\n",
    "        return self.X.shape[1]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Convert idx from tensor to list due to pandas bug (that arises when using pytorch's random_split)\n",
    "        if isinstance(idx, torch.Tensor):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        self.X.iloc[idx].values\n",
    "        self.y[idx]\n",
    "\n",
    "        return [self.X.iloc[idx].values, self.y[idx]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T08:08:50.194888Z",
     "start_time": "2020-11-29T08:08:49.538877Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trainset = ReadDataset(train_x,train_y)\n",
    "testset = ReadDataset(val_x,val_y)\n",
    "\n",
    "\n",
    "# Data loaders\n",
    "trainloader = DataLoader(trainset, batch_size=100, shuffle=True)\n",
    "# Test set\n",
    "\n",
    "X_train = torch.tensor(trainset.X.values)\n",
    "y_train = torch.tensor(trainset.y)\n",
    "\n",
    "X_test = torch.tensor(testset.X.values)\n",
    "y_test = torch.tensor(testset.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T08:08:50.211105Z",
     "start_time": "2020-11-29T08:08:50.197635Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use gpu if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T08:08:50.281573Z",
     "start_time": "2020-11-29T08:08:50.222435Z"
    }
   },
   "outputs": [],
   "source": [
    "# Neural Network\n",
    "nnet = Net(trainset.__shape__()).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T08:08:50.297545Z",
     "start_time": "2020-11-29T08:08:50.290199Z"
    }
   },
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "optimizer = optim.Adam(\n",
    "    nnet.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08,  # weight_decay=0.0001\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T08:15:04.703779Z",
     "start_time": "2020-11-29T08:08:50.301097Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(14.756340860174568, 57.05058314736424)\n",
      "5\n",
      "(15.2303357067158, 57.10303926373913)\n",
      "10\n",
      "(16.38497677258529, 61.74076209829261)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-1e96fb586fc6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-cb4456c6fd10>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    877\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 879\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1496\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1498\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ixs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_slice_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice_obj\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_ixs\u001b[0;34m(self, i, axis)\u001b[0m\n\u001b[1;32m   2835\u001b[0m                 \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2836\u001b[0m                 \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2837\u001b[0;31m                 \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2838\u001b[0m             )\n\u001b[1;32m   2839\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_is_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    325\u001b[0m                     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_cast_failure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSingleBlockManager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/construction.py\u001b[0m in \u001b[0;36msanitize_array\u001b[0;34m(data, index, dtype, copy, raise_cast_failure)\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0;31m# we will try to copy be-definition here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m             \u001b[0msubarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_try_cast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_cast_failure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCExtensionArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/construction.py\u001b[0m in \u001b[0;36m_try_cast\u001b[0;34m(arr, dtype, copy, raise_cast_failure)\u001b[0m\n\u001b[1;32m    537\u001b[0m     \u001b[0;31m# perf shortcut as this is the most common case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mmaybe_castable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    540\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/dtypes/cast.py\u001b[0m in \u001b[0;36mmaybe_castable\u001b[0;34m(arr)\u001b[0m\n\u001b[1;32m   1194\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mis_timedelta64_ns_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1196\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_POSSIBLY_CAST_DTYPES\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/numpy/core/_dtype.py\u001b[0m in \u001b[0;36m_name_get\u001b[0;34m(dtype)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# append bit counts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0m_name_includes_bit_suffix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitemsize\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/numpy/core/_dtype.py\u001b[0m in \u001b[0;36m_name_includes_bit_suffix\u001b[0;34m(dtype)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_name_includes_bit_suffix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobject_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m         \u001b[0;31m# pointer size varies by system, best to omit it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the net\n",
    "loss_per_iter = []\n",
    "loss_per_batch = []\n",
    "\n",
    "\n",
    "# Train the net\n",
    "losses = []\n",
    "auc_train = []\n",
    "auc_test = []\n",
    "metric_val = []\n",
    "unc_val = []\n",
    "\n",
    "# hyperparameteres\n",
    "n_epochs = 50\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    for i, (inputs, labels) in enumerate(trainloader):\n",
    "        X = inputs.to(device)\n",
    "        y = labels.to(device)\n",
    "\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forwarde\n",
    "        outputs = nnet(X.float())\n",
    "\n",
    "        # Compute diff\n",
    "\n",
    "        loss = interval_score_loss(outputs, y.float())\n",
    "\n",
    "        # Compute gradient\n",
    "        loss.backward()\n",
    "\n",
    "        # update weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Save loss to plot\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "        print(epoch)\n",
    "        auc_train.append(loss.cpu().detach().numpy())\n",
    "        pred = nnet(X_test.float())\n",
    "        auc_test.append(interval_score_loss(pred, y_test.float()))\n",
    "\n",
    "        preds = torch.mean(nnet(X_test.float()), axis=1).cpu().detach().numpy()\n",
    "        lower = nnet(X_test.float())[:, 0].cpu().detach().numpy()\n",
    "        upper = nnet(X_test.float())[:, 1].cpu().detach().numpy()\n",
    "        res = my_metric(preds, lower, upper)\n",
    "        print(res)\n",
    "        metric_val.append(res[0])\n",
    "        unc_val.append(res[1])\n",
    "\n",
    "        # Figure\n",
    "        plt.figure()\n",
    "        plt.plot(auc_train, label=\"train\")\n",
    "        plt.plot(auc_test, label=\"test\")\n",
    "        plt.plot(metric_val, label=\"Metric\")\n",
    "        plt.plot(unc_val, label=\"Uncertainty\")\n",
    "        plt.legend()\n",
    "        plt.ylim([0, 100])\n",
    "        plt.savefig(\"output/auc_NN.png\")\n",
    "        plt.savefig(\"output/auc_NN.svg\", format=\"svg\")\n",
    "        plt.close()\n",
    "\n",
    "        #\n",
    "        path = \"output/weights\" + str(epoch) + \".pt\"\n",
    "        torch.save(nnet.state_dict(), path)\n",
    "\n",
    "print(\"Elapsed time: \", np.abs(tic - time.time()))\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T08:15:04.713612Z",
     "start_time": "2020-11-29T08:07:54.932Z"
    }
   },
   "outputs": [],
   "source": [
    "def curation_post(data):\n",
    "    aux = data.copy()\n",
    "\n",
    "    # Save arrays\n",
    "    aux_low = aux[aux[\"pred_95_high\"] < aux[\"pred_95_low\"]].pred_95_low\n",
    "    aux_high = aux[aux[\"pred_95_high\"] < aux[\"pred_95_low\"]].pred_95_high\n",
    "    aux_index = aux[aux[\"pred_95_high\"] < aux[\"pred_95_low\"]].index\n",
    "\n",
    "    # Modify\n",
    "    aux.loc[aux_index, \"pred_95_low\"] = aux_high\n",
    "    aux.loc[aux_index, \"pred_95_high\"] = aux_low\n",
    "    \n",
    "    \n",
    "    if aux[aux[\"pred_95_high\"] < aux[\"pred_95_low\"]].shape[0]>0:\n",
    "        print('If errors they should appear: ')\n",
    "        print(aux[aux[\"pred_95_high\"] < aux[\"pred_95_low\"]].shape)\n",
    "        print(aux[aux[\"pred_95_high\"] < aux[\"pred_95_low\"]].shape)\n",
    "\n",
    "    preds_aux = np.mean([aux.pred_95_low, aux.pred_95_high], axis=0)\n",
    "    \n",
    "    aux['prediction'] = preds_aux\n",
    "    return aux\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T08:15:04.722963Z",
     "start_time": "2020-11-29T08:07:54.934Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict_withNN(NN, data):\n",
    "    # Make predictions\n",
    "    preds = torch.mean(NN(X_test.float()), axis=1).detach().numpy()\n",
    "    lower = NN(X_test.float())[:, 0].detach().numpy()\n",
    "    upper = NN(X_test.float())[:, 1].detach().numpy()\n",
    "\n",
    "    print(my_metric(preds, lower, upper))\n",
    "\n",
    "    # Modify offset\n",
    "    \n",
    "    #preds = (preds + 1) * val_offset\n",
    "    #lower = (lower + 1) * val_offset\n",
    "    #upper = (upper + 1) * val_offset\n",
    "\n",
    "    aux_data = data.copy()\n",
    "\n",
    "    aux_data[\"prediction\"] = preds\n",
    "    aux_data[\"pred_95_low\"] = lower\n",
    "    aux_data[\"pred_95_high\"] = upper\n",
    "\n",
    "    aux_data = curation_post(aux_data)\n",
    "    return aux_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T08:15:04.739269Z",
     "start_time": "2020-11-29T08:07:54.936Z"
    }
   },
   "outputs": [],
   "source": [
    "nnet60 = Net(trainset.__shape__()).to(device)\n",
    "nnet60.load_state_dict(torch.load(\"output/weights30.pt\",map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T08:15:04.778456Z",
     "start_time": "2020-11-29T08:07:54.938Z"
    }
   },
   "outputs": [],
   "source": [
    "nnet80 = Net(trainset.__shape__()).to(device)\n",
    "nnet80.load_state_dict(torch.load(\"output/weights35.pt\",map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T08:15:04.807525Z",
     "start_time": "2020-11-29T08:07:54.942Z"
    }
   },
   "outputs": [],
   "source": [
    "nnet95 = Net(trainset.__shape__()).to(device)\n",
    "nnet95.load_state_dict(torch.load(\"output/weights40.pt\",map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T08:15:04.840409Z",
     "start_time": "2020-11-29T08:07:54.945Z"
    }
   },
   "outputs": [],
   "source": [
    "nnet100 = Net(trainset.__shape__()).to(device)\n",
    "nnet100.load_state_dict(torch.load(\"output/weights45.pt\",map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T14:47:03.603639Z",
     "start_time": "2020-11-28T14:47:03.590667Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T08:15:04.851119Z",
     "start_time": "2020-11-29T08:07:54.948Z"
    }
   },
   "outputs": [],
   "source": [
    "n_60 = predict_withNN(nnet60,val_x_orig[['country','brand','month_num']])\n",
    "n_80 = predict_withNN(nnet80,val_x_orig[['country','brand','month_num']])\n",
    "n_95 = predict_withNN(nnet95,val_x_orig[['country','brand','month_num']])\n",
    "n_100 = predict_withNN(nnet100,val_x_orig[['country','brand','month_num']])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T08:15:04.855446Z",
     "start_time": "2020-11-29T08:07:54.952Z"
    }
   },
   "outputs": [],
   "source": [
    "n_val_final = n_100.copy()\n",
    "\n",
    "n_val_final.prediction = np.mean([n_60.prediction,\n",
    "                                n_80.prediction,\n",
    "                                n_95.prediction,\n",
    "                                n_100.prediction],axis=0)\n",
    "\n",
    "n_val_final.pred_95_low = np.mean([n_60.pred_95_low,\n",
    "                                n_80.pred_95_low,\n",
    "                                n_95.pred_95_low,\n",
    "                                n_100.pred_95_low],axis=0)\n",
    "\n",
    "n_val_final.pred_95_high = np.mean([n_60.pred_95_high,\n",
    "                                n_80.pred_95_high,\n",
    "                                n_95.pred_95_high,\n",
    "                                n_100.pred_95_high],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T08:15:04.862034Z",
     "start_time": "2020-11-29T08:07:54.954Z"
    }
   },
   "outputs": [],
   "source": [
    "my_metric(n_val_final.prediction,\n",
    "         n_val_final.pred_95_low,\n",
    "         n_val_final.pred_95_high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T08:15:04.864716Z",
     "start_time": "2020-11-29T08:07:54.955Z"
    }
   },
   "outputs": [],
   "source": [
    "# One Hot\n",
    "(11.703532084517162, 40.87996049931868)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T08:15:04.867534Z",
     "start_time": "2020-11-29T08:07:54.957Z"
    }
   },
   "outputs": [],
   "source": [
    "n_val_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T08:15:04.869975Z",
     "start_time": "2020-11-29T08:07:54.958Z"
    }
   },
   "outputs": [],
   "source": [
    "n_val_final.to_csv('output/valid_ensemble.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T08:15:04.872650Z",
     "start_time": "2020-11-29T08:07:54.960Z"
    }
   },
   "outputs": [],
   "source": [
    "def submission_predict(NN):\n",
    "\n",
    "    submission_df = pd.read_csv(\"../data/submission_template.csv\")\n",
    "\n",
    "    preds = torch.mean(NN(torch.tensor(test_x.values).float()), axis=1).detach().numpy()\n",
    "    lower = NN(torch.tensor(test_x.values).float())[:, 0].detach().numpy()\n",
    "    upper = NN(torch.tensor(test_x.values).float())[:, 1].detach().numpy()\n",
    "\n",
    "    preds = (preds + 1) * test_offset\n",
    "    lower = (lower + 1) * test_offset\n",
    "    upper = (upper + 1) * test_offset\n",
    "\n",
    "    submission_df[\"pred_95_low\"] = np.maximum(lower, 0)\n",
    "    submission_df[\"pred_95_high\"] = np.maximum(upper, 0)\n",
    "    submission_df[\"prediction\"] = np.maximum(preds, 0)\n",
    "    submission_df = curation_post(submission_df)\n",
    "\n",
    "    submission_df = postprocess_submission(submission_df)\n",
    "\n",
    "    submission_df[\"pred_95_low\"] = np.maximum(submission_df.pred_95_low, 0)\n",
    "    submission_df[\"pred_95_high\"] = np.maximum(submission_df.pred_95_high, 0)\n",
    "    submission_df[\"prediction\"] = np.maximum(submission_df.prediction, 0)\n",
    "\n",
    "    e = submission_df[\n",
    "        submission_df[\"pred_95_high\"] < submission_df[\"pred_95_low\"]\n",
    "    ].shape[0]\n",
    "    if e > 0:\n",
    "        print(\"WARNING:ERORR, please debug\")\n",
    "\n",
    "    e = submission_df[\n",
    "        submission_df[\"pred_95_low\"] > submission_df[\"pred_95_high\"]\n",
    "    ].shape[0]\n",
    "    if e > 0:\n",
    "        print(\"WARNING:ERORR, please debug\")\n",
    "\n",
    "    e = submission_df[\n",
    "        submission_df[\"prediction\"] > submission_df[\"pred_95_high\"]\n",
    "    ].shape[0]\n",
    "    if e > 0:\n",
    "        print(\"WARNING:ERORR, please debug\")\n",
    "\n",
    "    e = submission_df[submission_df[\"prediction\"] < submission_df[\"pred_95_low\"]].shape[\n",
    "        0\n",
    "    ]\n",
    "    if e > 0:\n",
    "        print(\"WARNING:ERORR, please debug\")\n",
    "    return submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T08:15:04.876918Z",
     "start_time": "2020-11-29T08:07:54.961Z"
    }
   },
   "outputs": [],
   "source": [
    "pred60 = submission_predict(nnet60)\n",
    "pred80 = submission_predict(nnet80)\n",
    "pred95 = submission_predict(nnet60)\n",
    "pred100 = submission_predict(nnet80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T08:15:04.879832Z",
     "start_time": "2020-11-29T08:07:54.963Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_final = pred60.copy()\n",
    "\n",
    "pred_final.prediction = np.mean(\n",
    "    [pred60.prediction, pred80.prediction, pred95.prediction, pred100.prediction],\n",
    "    axis=0,\n",
    ")\n",
    "\n",
    "pred_final.pred_95_low = np.mean(\n",
    "    [pred60.pred_95_low, pred80.pred_95_low, pred95.pred_95_low, pred100.pred_95_low],\n",
    "    axis=0,\n",
    ")\n",
    "\n",
    "pred_final.pred_95_high = np.mean(\n",
    "    [\n",
    "        pred60.pred_95_high,\n",
    "        pred80.pred_95_high,\n",
    "        pred95.pred_95_high,\n",
    "        pred100.pred_95_high,\n",
    "    ],\n",
    "    axis=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T08:15:04.884095Z",
     "start_time": "2020-11-29T08:07:54.965Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_final.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T08:15:04.887733Z",
     "start_time": "2020-11-29T08:07:54.966Z"
    }
   },
   "outputs": [],
   "source": [
    "pred60.to_csv(\"../submissions/pred60_noPost.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T08:15:04.903453Z",
     "start_time": "2020-11-29T08:07:54.968Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_final.to_csv(\"../submissions/pred_final.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pred final vanilla on val\n",
    "(11.54, 40.81)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T09:23:49.647289Z",
     "start_time": "2020-11-29T09:23:49.628524Z"
    }
   },
   "outputs": [],
   "source": [
    "def postprocess_submission(submission_df, solve_submission_issues=True):\n",
    "\n",
    "    join_on = [\"country\", \"brand\", \"month_num\"]\n",
    "    keep = join_on + [\"volume\"]\n",
    "\n",
    "    df_vol = pd.read_csv(\"../data/gx_volume.csv\").loc[:, keep]\n",
    "\n",
    "    both_ds = submission_df.merge(\n",
    "        df_vol,\n",
    "        on=join_on,\n",
    "        how=\"left\",\n",
    "    )\n",
    "\n",
    "    both_ds.loc[both_ds[\"volume\"].notnull(), \"prediction\"] = both_ds[both_ds[\"volume\"].notnull()][\"volume\"].values\n",
    "    both_ds.loc[both_ds[\"volume\"].notnull(), \"pred_95_high\"] = both_ds[both_ds[\"volume\"].notnull()][\"volume\"].values + 0.01\n",
    "    both_ds.loc[both_ds[\"volume\"].notnull(), \"pred_95_low\"] = both_ds[both_ds[\"volume\"].notnull()][\"volume\"].values - 0.01\n",
    "\n",
    "    final_cols = join_on + [\"pred_95_low\", \"prediction\", \"pred_95_high\"]\n",
    "\n",
    "    final_df =  both_ds.loc[:, final_cols]\n",
    "\n",
    "    if solve_submission_issues:\n",
    "\n",
    "        if (final_df.pred_95_low > final_df.pred_95_high).any():\n",
    "            print(np.sum(final_df.pred_95_low > final_df.pred_95_high))\n",
    "            raise(\"Stop please, upper < lower\")\n",
    "\n",
    "        cond_lower_mean = final_df.pred_95_low > final_df.prediction\n",
    "        if cond_lower_mean.any():\n",
    "            print(\"Solving lower > mean\")\n",
    "            print(np.sum(final_df.pred_95_low > final_df.prediction))\n",
    "            final_df.loc[cond_lower_mean, \"prediction\"] = \\\n",
    "                final_df.loc[cond_lower_mean, \"pred_95_low\"] + 0.01\n",
    "\n",
    "        cond_upper_mean = final_df.prediction > final_df.pred_95_high\n",
    "        if cond_upper_mean.any():\n",
    "            print(\"Solving upper < mean\")\n",
    "            final_df.loc[cond_upper_mean, \"prediction\"] = \\\n",
    "                final_df.loc[cond_upper_mean, \"pred_95_high\"] - 0.01\n",
    "\n",
    "\n",
    "    return final_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T09:23:50.060694Z",
     "start_time": "2020-11-29T09:23:50.042282Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/SUBMISSION CORRECTED.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T09:23:50.493021Z",
     "start_time": "2020-11-29T09:23:50.347164Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving lower > mean\n",
      "140\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>brand</th>\n",
       "      <th>month_num</th>\n",
       "      <th>pred_95_low</th>\n",
       "      <th>prediction</th>\n",
       "      <th>pred_95_high</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>country_1</td>\n",
       "      <td>brand_121</td>\n",
       "      <td>0</td>\n",
       "      <td>3.327128e+07</td>\n",
       "      <td>3.327128e+07</td>\n",
       "      <td>3.327128e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>country_1</td>\n",
       "      <td>brand_121</td>\n",
       "      <td>1</td>\n",
       "      <td>1.276786e+07</td>\n",
       "      <td>1.276786e+07</td>\n",
       "      <td>1.276786e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>country_1</td>\n",
       "      <td>brand_121</td>\n",
       "      <td>2</td>\n",
       "      <td>7.870697e+06</td>\n",
       "      <td>7.870697e+06</td>\n",
       "      <td>7.870697e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>country_1</td>\n",
       "      <td>brand_121</td>\n",
       "      <td>3</td>\n",
       "      <td>6.978249e+06</td>\n",
       "      <td>6.978249e+06</td>\n",
       "      <td>6.978249e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>country_1</td>\n",
       "      <td>brand_121</td>\n",
       "      <td>4</td>\n",
       "      <td>7.223489e+06</td>\n",
       "      <td>7.223489e+06</td>\n",
       "      <td>7.223489e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4579</th>\n",
       "      <td>country_9</td>\n",
       "      <td>brand_187</td>\n",
       "      <td>19</td>\n",
       "      <td>1.596853e+07</td>\n",
       "      <td>2.453214e+07</td>\n",
       "      <td>3.435900e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4580</th>\n",
       "      <td>country_9</td>\n",
       "      <td>brand_187</td>\n",
       "      <td>20</td>\n",
       "      <td>1.343837e+07</td>\n",
       "      <td>2.138781e+07</td>\n",
       "      <td>3.060052e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4581</th>\n",
       "      <td>country_9</td>\n",
       "      <td>brand_187</td>\n",
       "      <td>21</td>\n",
       "      <td>1.374823e+07</td>\n",
       "      <td>2.080449e+07</td>\n",
       "      <td>2.911921e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4582</th>\n",
       "      <td>country_9</td>\n",
       "      <td>brand_187</td>\n",
       "      <td>22</td>\n",
       "      <td>7.453335e+06</td>\n",
       "      <td>1.567176e+07</td>\n",
       "      <td>2.566832e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4583</th>\n",
       "      <td>country_9</td>\n",
       "      <td>brand_187</td>\n",
       "      <td>23</td>\n",
       "      <td>9.423787e+06</td>\n",
       "      <td>1.521937e+07</td>\n",
       "      <td>2.215538e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4584 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        country      brand  month_num   pred_95_low    prediction  \\\n",
       "0     country_1  brand_121          0  3.327128e+07  3.327128e+07   \n",
       "1     country_1  brand_121          1  1.276786e+07  1.276786e+07   \n",
       "2     country_1  brand_121          2  7.870697e+06  7.870697e+06   \n",
       "3     country_1  brand_121          3  6.978249e+06  6.978249e+06   \n",
       "4     country_1  brand_121          4  7.223489e+06  7.223489e+06   \n",
       "...         ...        ...        ...           ...           ...   \n",
       "4579  country_9  brand_187         19  1.596853e+07  2.453214e+07   \n",
       "4580  country_9  brand_187         20  1.343837e+07  2.138781e+07   \n",
       "4581  country_9  brand_187         21  1.374823e+07  2.080449e+07   \n",
       "4582  country_9  brand_187         22  7.453335e+06  1.567176e+07   \n",
       "4583  country_9  brand_187         23  9.423787e+06  1.521937e+07   \n",
       "\n",
       "      pred_95_high  \n",
       "0     3.327128e+07  \n",
       "1     1.276786e+07  \n",
       "2     7.870697e+06  \n",
       "3     6.978249e+06  \n",
       "4     7.223489e+06  \n",
       "...            ...  \n",
       "4579  3.435900e+07  \n",
       "4580  3.060052e+07  \n",
       "4581  2.911921e+07  \n",
       "4582  2.566832e+07  \n",
       "4583  2.215538e+07  \n",
       "\n",
       "[4584 rows x 6 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postprocess_submission(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
